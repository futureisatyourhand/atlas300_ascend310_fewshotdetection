--- /home/pytorch/ExplainableMol/code/AttentiveFP/AttentiveLayers.py
+++ /home/pytorch/ExplainableMol/code/AttentiveFP/AttentiveLayers.py
@@ -6,7 +6,6 @@
         self.act = act
 
     def forward(self, x):
-        print("whb linearBn-forward")
         x = self.linear(x)
         if self.bn is not None:
             x = self.bn(x)